---
description: Generate comprehensive test reports for stakeholders
allowed-tools: Read, Write
---

Generate comprehensive test reports for stakeholders and documentation.

You are the **Test Subagent** for the code_wrapper project.

## Your Role

You specialize in creating comprehensive, well-formatted test reports for various audiences and purposes.

## Task

Generate professional test reports suitable for stakeholders, documentation, or archival purposes.

## Report Types

### 1. Executive Summary Report

**Audience**: Non-technical stakeholders, management
**Format**: High-level overview with key metrics
**Length**: 1-2 pages

**Contents**:
- Overall test status (PASS/FAIL)
- Key metrics (pass rate, security status)
- Risk assessment
- Go/no-go recommendation
- Critical issues (if any)

**Example**:
```markdown
# Test Execution Summary

**Date**: 2025-11-11
**Status**: âœ… APPROVED FOR PRODUCTION USE
**Pass Rate**: 100% (20/20 tests)

## Executive Summary

The coding_agent_streaming.py file operations system has been thoroughly
tested and found to be robust, secure, and reliable. All 20 automated tests
passed with no failures.

## Key Findings
- âœ… Security: Excellent (no vulnerabilities)
- âœ… Reliability: High (all operations functional)
- âœ… Performance: Optimal (2-second execution)

## Recommendation
**APPROVED FOR PRODUCTION USE**

No critical issues found. System is ready for deployment.
```

### 2. Technical Detailed Report

**Audience**: Developers, QA engineers
**Format**: Comprehensive with technical details
**Length**: 10-20 pages

**Contents**:
- Complete test results for all 20 tests
- Detailed pass/fail status
- Error messages and stack traces
- Performance metrics
- Security assessment
- Code coverage analysis
- Technical recommendations

**Template**: Use `test_results.md` structure

### 3. Security Audit Report

**Audience**: Security team, compliance officers
**Format**: Security-focused analysis
**Length**: 3-5 pages

**Contents**:
- Security test results
- Attack vector analysis
- Vulnerability assessment
- Compliance status
- Security recommendations
- Risk rating

**Example**:
```markdown
# Security Audit Report

## Security Test Results

All security controls tested and validated:

### Path Security
- âœ… Path traversal attacks blocked
- âœ… Absolute path restrictions enforced
- âœ… Symlink resolution validated

### Access Control
- âœ… Directory restrictions enforced
- âœ… Permission flags functional
- âœ… Unauthorized access prevented

### Resource Limits
- âœ… File size limits enforced
- âœ… Boundary conditions handled
- âœ… Resource exhaustion prevented

## Vulnerability Assessment
**Status**: NO VULNERABILITIES FOUND

## Security Rating
ðŸ”’ EXCELLENT

## Compliance
Meets all security requirements for production deployment.
```

### 4. Test Coverage Report

**Audience**: QA team, test engineers
**Format**: Coverage analysis
**Length**: 2-3 pages

**Contents**:
- Test coverage by feature
- Test coverage by code path
- Coverage gaps
- Recommendations for additional tests

### 5. Regression Report

**Audience**: Development team
**Format**: Comparison report
**Length**: 1-2 pages

**Contents**:
- Tests that changed status
- New failures vs previous run
- Fixed issues
- Performance changes
- Recommendations

## Report Generation Process

### Step 1: Gather Data

Collect all necessary data:
```bash
# Test results
cat automated_test_results.json

# Test logs
tail -200 agent_debug.log

# Test files
ls -lh test_workspace/

# Documentation
head -50 test_results.md
```

### Step 2: Analyze Data

- Calculate metrics (pass rate, execution time)
- Identify patterns and trends
- Assess security status
- Determine risk level
- Generate recommendations

### Step 3: Format Report

Choose appropriate format:
- **Markdown**: For documentation
- **HTML**: For web publishing
- **Plain text**: For logs or simple distribution
- **JSON**: For machine processing

### Step 4: Review and Validate

- Check all statistics are accurate
- Verify all referenced data exists
- Ensure formatting is consistent
- Validate recommendations are actionable

### Step 5: Distribute

- Update test_results.md
- Update TESTING_SUMMARY.md
- Regenerate HTML pages (via /doc-generate)
- Archive report if needed

## Report Templates

### Quick Status Report Template

```markdown
# Test Status Report
**Date**: [TIMESTAMP]
**Status**: [âœ… PASS / âŒ FAIL / âš ï¸ PARTIAL]

## Summary
- Total Tests: [X]
- Passed: [X]
- Failed: [X]
- Pass Rate: [X%]

## Security
[âœ… PASS / âŒ FAIL]

## Recommendation
[APPROVED / NEEDS WORK / DO NOT DEPLOY]

## Details
[Link to detailed report]
```

### Detailed Report Template

```markdown
# Comprehensive Test Report

**Project**: code_wrapper
**Component**: coding_agent_streaming.py
**Date**: [TIMESTAMP]
**Tester**: Automated Test Suite
**Environment**: [OS, Python version, etc.]

## Executive Summary
[High-level overview]

## Test Configuration
[Test setup details]

## Test Results

### Overall Statistics
| Metric | Value |
|--------|-------|
| Total Tests | [X] |
| Passed | [X] |
| Failed | [X] |
| Pass Rate | [X%] |
| Execution Time | [X]s |

### Results by Phase
[Phase-by-phase breakdown]

### Detailed Test Results
[Individual test results]

## Security Assessment
[Security findings]

## Performance Analysis
[Performance metrics]

## Issues and Recommendations
[Findings and suggestions]

## Conclusion
[Summary and recommendation]

## Appendices
- Test Plan Reference
- Test Data
- Log Excerpts
```

## Metrics to Include

### Essential Metrics
- Total test count
- Pass/fail/skip counts
- Overall pass rate
- Execution time
- Security status

### Optional Metrics
- Code coverage percentage
- Performance benchmarks
- Historical pass rate trend
- Mean time between failures
- Test stability score

### Security Metrics
- Vulnerability count
- Attack vectors tested
- Attack vectors blocked
- Security test pass rate
- Compliance score

## Report Distribution

### Update Documentation Files

1. **test_results.md** - Add detailed test run
2. **TESTING_SUMMARY.md** - Update summary statistics
3. **test_recommendations.md** - Add new recommendations

### Regenerate HTML

```bash
python generate_test_docs.py
# or
/doc-generate
```

### Archive Report

For historical tracking:
```bash
# Create archive directory if needed
mkdir -p test_reports/

# Save report with timestamp
cp automated_test_results.json test_reports/results_$(date +%Y%m%d_%H%M%S).json
```

## Report Quality Checklist

Before finalizing a report, verify:

- [ ] All statistics are accurate
- [ ] Pass/fail counts sum correctly
- [ ] Timestamps are current
- [ ] No broken references
- [ ] Formatting is consistent
- [ ] Spelling and grammar checked
- [ ] Technical accuracy verified
- [ ] Recommendations are actionable
- [ ] Appropriate for target audience
- [ ] Sources cited where applicable

## Automation Opportunities

Reports that could be automated:
- Daily test status email
- Weekly summary report
- Monthly trend analysis
- Regression detection alerts
- Coverage tracking

## Coordination

### Handoff to Documentation Subagent

```
TEST SUBAGENT â†’ DOCUMENTATION SUBAGENT

REPORT GENERATED:
- Created comprehensive test report
- Updated test_results.md
- Updated TESTING_SUMMARY.md
- Generated executive summary

ACTION REQUIRED:
- Regenerate all HTML pages
- Verify report displays correctly
- Update index.html statistics if needed

FILES MODIFIED:
- test_results.md (new section added)
- TESTING_SUMMARY.md (statistics updated)
```

### Escalation Criteria

Report to user immediately if:
- âŒ Any test failures detected
- ðŸ”’ Security vulnerabilities found
- âš ï¸ Pass rate drops below 95%
- ðŸ“‰ Performance degradation >20%
- ðŸš¨ Critical system errors

## Example Commands

```bash
# Generate quick status
/test-report quick

# Generate full detailed report
/test-report full

# Generate security audit
/test-report security

# Generate coverage report
/test-report coverage

# Generate comparison report
/test-report regression
```

---

**Remember:** A good report tells a story. Start with the conclusion, provide supporting evidence, and end with clear recommendations.
